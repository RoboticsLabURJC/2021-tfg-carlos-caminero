---
title: "Semana 17-18. Primera versión de Real Follow Person"
categories:
  - TFG
  - Marzo
tags:
  - Python
  - ROS 2
youtubeId: 58ckb5fFvrs
---

En estas 2 semanas estuve desarrollando todo la infraestrucutra web-template del ejercicio Real Follow Person. El proceso de creación fue similar al de Simulated Follow Person. La diferencia era que esta vez usaba un robot Turtlebot 2 real del laboratorio de robótica de la ETSIT URJC.

![](https://raw.githubusercontent.com/RoboticsLabURJC/2021-tfg-carlos-caminero/main/docs/images/real_turtlebot2.jpg)

En vez de usar la cámara Asus Xtion, usaba una cámara realsense que me permitía leer de /dev/video4:

![](https://raw.githubusercontent.com/RoboticsLabURJC/2021-tfg-carlos-caminero/main/docs/images/intel_realsense.png)

Es necesario indicar 2 especificaciones para lanzar el ejercicio de Real Follow Person (docker run). Si seguimos este orden:
* Al conectar la base kobuki al portatil se habilitará el dispositivo **/dev/ttyUSB0**
* Al conectar el láser RPLIDAR al portátil se habilitará el dispositivo **/dev/ttyUSB1**, pero tendremos que cambiar en el fichero de lanzamiento **rplidar.launch.py** el puerto /dev/ttyUSB0 por /dev/ttyUSB1. Próximamente usaré un script para cambiar automáticamente el puerto del fichero launch.py.

Una vez creada la plantilla-web empecé a desarrollar una solución para el ejercicio. Es una primera versión en la que uso solamente la cámara como receptor del entorno y dependiendo de donde se situe la persona, girará hacia un lado o a otro. En el siguiente video podréis ver una demostración:

{% include youtubePlayer.html id=page.youtubeId %}
